version: '3.8'

services:
  postgres-airflow:
    image: postgres:15
    container_name: postgres-airflow
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    ports:
      - "5432:5432"
    volumes:
      - postgres_airflow_data:/var/lib/postgresql/data

  postgres-data:
    image: postgres:15
    container_name: postgres-data
    environment:
      POSTGRES_USER: data_user
      POSTGRES_PASSWORD: data_password
      POSTGRES_DB: data_db
    ports:
      - "5433:5432" # Porta 5433 mapeada para evitar conflito
    volumes:
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql

  airflow-webserver:
    build:
      context: ./orquestrador  # Caminho para o diretório onde está o Dockerfile.airflow
      dockerfile: Dockerfile.airflow
    container_name: airflow-webserver
    depends_on:
      - postgres-airflow
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres-airflow:5432/airflow
    ports:
      - "8080:8080"
    command: >
      bash -c "
      airflow db init &&
      airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com &&
      airflow db upgrade &&
      airflow webserver"

  airflow-scheduler:
    build:
      context: ./orquestrador  # Caminho para o diretório onde está o Dockerfile.airflow
      dockerfile: Dockerfile.airflow
    container_name: airflow-scheduler
    depends_on:
      - postgres-airflow
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres-airflow:5432/airflow
    command: airflow scheduler

  spark-master:
    build:
      context: .  # Contexto do build do Spark
    container_name: spark-master
    environment:
      SPARK_MODE: master
      SPARK_MASTER: spark://spark-master:7077  # Isso já está correto, pois é o nome do serviço
    ports:
      - "7077:7077"   # Porta para o Spark Master
      - "8081:8081"   # Porta para a UI do Spark Master
    volumes:
      - .:/app
    working_dir: /app
    networks:
      - spark-net

  spark-worker:
    build:
      context: .  # Contexto do build do Spark
    container_name: spark-worker
    environment:
      SPARK_MODE: worker
      SPARK_MASTER_URL: spark://spark-master:7077  # Conexão com o Spark Master usando o nome do serviço
    depends_on:
      - spark-master
    ports:
      - "8082:8082"   # UI do Spark Worker
    volumes:
      - .:/app
    working_dir: /app
    networks:
      - spark-net

networks:
  spark-net:  # Criando uma rede para os containers de Spark

volumes:
  postgres_airflow_data:
  postgres_data_data:
